
cuda is not avaiable.

==================================================
goal = test
device = cpu
device_id = 0
dataset = HAR
num_classes = 10
model = HARCNN
batch_size = 10
local_learning_rate = 0.01
learning_rate_decay = False
learning_rate_decay_gamma = 0.99
global_rounds = 100
top_cnt = 100
local_epochs = 10
algorithm = FedAvg
join_ratio = 0.5
random_join_ratio = False
num_clients = 20
prev = 0
times = 1
eval_gap = 1
save_folder_name = items
auto_break = False
dlg_eval = False
dlg_gap = 100
batch_num_per_client = 2
num_new_clients = 0
fine_tuning_epoch_new = 0
feature_dim = 512
vocab_size = 80
max_len = 200
few_shot = 0
client_drop_rate = 0.0
train_slow_rate = 0.0
send_slow_rate = 0.0
time_select = False
time_threthold = 10000
beta = 0.0
lamda = 1.0
mu = 0.0
K = 5
p_learning_rate = 0.01
M = 5
itk = 4000
alphaK = 1.0
sigma = 1.0
alpha = 1.0
plocal_epochs = 1
tau = 1.0
fine_tuning_epochs = 10
dr_learning_rate = 0.0
L = 1.0
noise_dim = 512
generator_learning_rate = 0.005
hidden_dim = 512
server_epochs = 1000
localize_feature_extractor = False
server_learning_rate = 1.0
eta = 1.0
rand_percent = 80
layer_idx = 2
mentee_learning_rate = 0.005
T_start = 0.95
T_end = 0.98
momentum = 0.1
kl_weight = 0.0
num_candidates = 0
method = RandomSelect
comment =
num_clients_per_round = 10
num_available = None
loss_div_sqrt = False
loss_sum = False
total_num_clients = 20
num_epoch = 10
wandb = True
==================================================

============= Running time: 0th =============
Creating server and clients ...
HARCNN(
  (conv1): Sequential(
    (0): Conv2d(9, 32, kernel_size=(1, 9), stride=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=(1, 2), stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (conv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(1, 9), stride=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=(1, 2), stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Linear(in_features=1664, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)
Initializing client selection method: RandomSelect

Join ratio / total clients: 0.5 / 20
Finished creating server and clients.

------------- Round 0-------------
> Pre-training selection: choosing 10 clients.
> Sending global model to 10 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 2.3169
Averaged Test Accurancy: 0.0000
Averaged Test AUC: 0.2801
Std Test Accurancy: 0.0000
Std Test AUC: 0.0148
--- Training 10 clients ---
> Aggregating models from 10 final selected clients.
------------------------- time cost ------------------------- 29.127581119537354

------------- Round 1-------------
> Pre-training selection: choosing 10 clients.
> Sending global model to 10 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 2.0078
Averaged Test Accurancy: 0.1558
Averaged Test AUC: 0.5427
Std Test Accurancy: 0.1627
Std Test AUC: 0.2598
--- Training 10 clients ---
> Aggregating models from 10 final selected clients.
------------------------- time cost ------------------------- 30.130849361419678

------------- Round 2-------------
> Pre-training selection: choosing 10 clients.
> Sending global model to 10 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 1.6835
Averaged Test Accurancy: 0.2721
Averaged Test AUC: 0.6677
Std Test Accurancy: 0.2151
Std Test AUC: 0.2768
--- Training 10 clients ---
> Aggregating models from 10 final selected clients.
------------------------- time cost ------------------------- 41.76854085922241

------------- Round 3-------------
> Pre-training selection: choosing 10 clients.
> Sending global model to 10 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 1.4333
Averaged Test Accurancy: 0.3954
Averaged Test AUC: 0.8100
Std Test Accurancy: 0.1727
Std Test AUC: 0.1721
--- Training 10 clients ---
> Aggregating models from 10 final selected clients.
------------------------- time cost ------------------------- 72.05050015449524

------------- Round 4-------------
> Pre-training selection: choosing 10 clients.
> Sending global model to 10 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 1.2077
Averaged Test Accurancy: 0.5015
Averaged Test AUC: 0.8777
Std Test Accurancy: 0.1783
Std Test AUC: 0.0574
--- Training 10 clients ---
> Aggregating models from 10 final selected clients.
------------------------- time cost ------------------------- 67.26212096214294

------------- Round 5-------------
> Pre-training selection: choosing 10 clients.
> Sending global model to 10 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.9673
Averaged Test Accurancy: 0.5868
Averaged Test AUC: 0.8969
Std Test Accurancy: 0.1945
Std Test AUC: 0.0543
--- Training 10 clients ---
> Aggregating models from 10 final selected clients.
------------------------- time cost ------------------------- 70.9060115814209

------------- Round 6-------------
> Pre-training selection: choosing 10 clients.
> Sending global model to 10 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.7788
Averaged Test Accurancy: 0.6594
Averaged Test AUC: 0.9111
Std Test Accurancy: 0.2093
Std Test AUC: 0.0508
--- Training 10 clients ---
> Aggregating models from 10 final selected clients.
------------------------- time cost ------------------------- 69.19644618034363

------------- Round 7-------------
> Pre-training selection: choosing 10 clients.
> Sending global model to 10 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.6150
Averaged Test Accurancy: 0.7350
Averaged Test AUC: 0.9310
Std Test Accurancy: 0.1518
Std Test AUC: 0.0231
--- Training 10 clients ---
Traceback (most recent call last):
  File "C:\Program Files\Python37\lib\runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "C:\Program Files\Python37\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_latest\main.py", line 323, in <module>
    run(args, client_selection)
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_latest\main.py", line 116, in run
    server.train()
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_latest\flcore\servers\serveravg.py", line 140, in train
    local_losses, accuracy, local_metrics = self.train_clients(clients_to_train)
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_latest\flcore\servers\serverbase.py", line 430, in train_clients
    train_result = client.train()
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_latest\flcore\clients\clientavg.py", line 56, in train
    loss.backward()
  File "C:\Users\owner\AppData\Roaming\Python\Python37\site-packages\torch\tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\owner\AppData\Roaming\Python\Python37\site-packages\torch\autograd\__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
