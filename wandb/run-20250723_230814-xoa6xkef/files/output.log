
cuda is not avaiable.

==================================================
goal = test
device = cpu
device_id = 0
dataset = HAR
num_classes = 6
model = HARCNN
batch_size = 10
local_learning_rate = 0.01
learning_rate_decay = False
learning_rate_decay_gamma = 0.99
global_rounds = 100
top_cnt = 100
local_epochs = 10
algorithm = FedAvg
join_ratio = 0.2
random_join_ratio = False
num_clients = 20
prev = 0
times = 1
eval_gap = 1
save_folder_name = items
auto_break = False
dlg_eval = False
dlg_gap = 100
batch_num_per_client = 2
num_new_clients = 0
fine_tuning_epoch_new = 0
feature_dim = 512
vocab_size = 80
max_len = 200
few_shot = 0
client_drop_rate = 0.0
train_slow_rate = 0.0
send_slow_rate = 0.0
time_select = False
time_threthold = 10000
beta = 0.0
lamda = 1.0
mu = 0.0
K = 5
p_learning_rate = 0.01
M = 5
itk = 4000
alphaK = 1.0
sigma = 1.0
alpha = 1.0
plocal_epochs = 1
tau = 1.0
fine_tuning_epochs = 10
dr_learning_rate = 0.0
L = 1.0
noise_dim = 512
generator_learning_rate = 0.005
hidden_dim = 512
server_epochs = 1000
localize_feature_extractor = False
server_learning_rate = 0.1
eta = 1.0
rand_percent = 80
layer_idx = 2
mentee_learning_rate = 0.005
T_start = 0.95
T_end = 0.98
momentum = 0.1
kl_weight = 0.0
num_candidates = 0
method = RandomSelect
comment =
num_clients_per_round = 4
num_available = None
loss_div_sqrt = False
loss_sum = False
subset_ratio = 0.1
alpha1 = 0.75
alpha2 = 1
alpha3 = 0.1
save_probs = False
no_save_results = False
src_id = 8
total_num_clients = 20
num_epoch = 10
wandb = True
==================================================

****** Client source: 8 *******
Accuracy of source client: 87.36%

============= Running time: 0th =============
Creating server and clients ...
HARCNN
Initializing client selection method: RandomSelect

Join ratio / total clients: 0.2 / 20
Finished creating server and clients.

------------- Round 0-------------
> Pre-training selection: choosing 4 clients.
SELECTED INDICES:  [ 5  6  3 17]
DEBUG: About to index self.clients. Length of self.clients is: 20
> Sending global model to 4 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 2.0901
Averaged Test Accurancy: 0.4269
Averaged Test AUC: 0.8233
Std Test Accurancy: 0.1837
Std Test AUC: 0.0739
--- Training 4 clients ---
> Aggregating models from 4 final selected clients.
> Selected client IDs for this round: [3, 5, 6, 17]
------------------------- time cost ------------------------- 425.7187807559967

------------- Round 1-------------
> Pre-training selection: choosing 4 clients.
SELECTED INDICES:  [ 9  2 11 14]
DEBUG: About to index self.clients. Length of self.clients is: 20
> Sending global model to 4 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 1.0844
Averaged Test Accurancy: 0.6761
Averaged Test AUC: 0.8769
Std Test Accurancy: 0.0809
Std Test AUC: 0.0369
--- Training 4 clients ---
> Aggregating models from 4 final selected clients.
> Selected client IDs for this round: [2, 9, 11, 14]
------------------------- time cost ------------------------- 411.6995930671692

------------- Round 2-------------
> Pre-training selection: choosing 4 clients.
SELECTED INDICES:  [18 16  9  6]
DEBUG: About to index self.clients. Length of self.clients is: 20
> Sending global model to 4 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 1.6500
Averaged Test Accurancy: 0.5939
Averaged Test AUC: 0.7618
Std Test Accurancy: 0.0991
Std Test AUC: 0.0680
--- Training 4 clients ---
> Aggregating models from 4 final selected clients.
> Selected client IDs for this round: [6, 9, 16, 18]
------------------------- time cost ------------------------- 435.2874035835266

------------- Round 3-------------
> Pre-training selection: choosing 4 clients.
SELECTED INDICES:  [19 17  5  9]
DEBUG: About to index self.clients. Length of self.clients is: 20
> Sending global model to 4 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 1.6358
Averaged Test Accurancy: 0.5929
Averaged Test AUC: 0.7745
Std Test Accurancy: 0.0731
Std Test AUC: 0.0674
--- Training 4 clients ---
> Aggregating models from 4 final selected clients.
> Selected client IDs for this round: [5, 9, 17, 19]
------------------------- time cost ------------------------- 522.3338675498962

------------- Round 4-------------
> Pre-training selection: choosing 4 clients.
SELECTED INDICES:  [ 3 12  4 18]
DEBUG: About to index self.clients. Length of self.clients is: 20
> Sending global model to 4 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 1.7384
Averaged Test Accurancy: 0.5381
Averaged Test AUC: 0.7541
Std Test Accurancy: 0.0746
Std Test AUC: 0.0536
--- Training 4 clients ---
Traceback (most recent call last):
  File "C:\Program Files\Python37\lib\runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "C:\Program Files\Python37\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_shot\main.py", line 235, in <module>
    run(args, client_selection)
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_shot\main.py", line 145, in run
    server.train()
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_shot\flcore\servers\serveravg.py", line 151, in train
    local_losses, accuracy, local_metrics = self.train_clients(clients_for_training)
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_shot\flcore\servers\serverbase.py", line 453, in train_clients
    train_result = client.train()
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_shot\flcore\clients\clientavg.py", line 38, in train
    result=self.model.update(trainloader)
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_shot\flcore\algorithms\algorithms.py", line 132, in update
    loss.backward()
  File "C:\Users\owner\AppData\Roaming\Python\Python37\site-packages\torch\tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\owner\AppData\Roaming\Python\Python37\site-packages\torch\autograd\__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
