
cuda is not avaiable.

==================================================
goal = test
device = cpu
device_id = 0
dataset = HAR
num_classes = 10
model = HARCNN
batch_size = 10
local_learning_rate = 0.01
learning_rate_decay = False
learning_rate_decay_gamma = 0.99
global_rounds = 100
top_cnt = 100
local_epochs = 10
algorithm = FedAvg
join_ratio = 0.5
random_join_ratio = False
num_clients = 20
prev = 0
times = 1
eval_gap = 1
save_folder_name = items
auto_break = False
dlg_eval = False
dlg_gap = 100
batch_num_per_client = 2
num_new_clients = 0
fine_tuning_epoch_new = 0
feature_dim = 512
vocab_size = 80
max_len = 200
few_shot = 0
client_drop_rate = 0.0
train_slow_rate = 0.0
send_slow_rate = 0.0
time_select = False
time_threthold = 10000
beta = 0.0
lamda = 1.0
mu = 0.0
K = 5
p_learning_rate = 0.01
M = 5
itk = 4000
alphaK = 1.0
sigma = 1.0
alpha = 1.0
plocal_epochs = 1
tau = 1.0
fine_tuning_epochs = 10
dr_learning_rate = 0.0
L = 1.0
noise_dim = 512
generator_learning_rate = 0.005
hidden_dim = 512
server_epochs = 1000
localize_feature_extractor = False
server_learning_rate = 1.0
eta = 1.0
rand_percent = 80
layer_idx = 2
mentee_learning_rate = 0.005
T_start = 0.95
T_end = 0.98
momentum = 0.1
kl_weight = 0.0
num_candidates = 0
method = DivFL
comment =
num_clients_per_round = 10
num_available = None
loss_div_sqrt = False
loss_sum = False
subset_ratio = 0.1
alpha1 = 0.75
alpha2 = 1
alpha3 = 0.1
save_probs = False
no_save_results = False
total_num_clients = 20
num_epoch = 10
wandb = True
==================================================

============= Running time: 0th =============
Creating server and clients ...
HARCNN(
  (conv1): Sequential(
    (0): Conv2d(9, 32, kernel_size=(1, 9), stride=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=(1, 2), stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (conv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(1, 9), stride=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=(1, 2), stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc): Sequential(
    (0): Linear(in_features=1664, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)
Initializing client selection method: DivFL

Join ratio / total clients: 0.5 / 20
Finished creating server and clients.

------------- Round 0-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 2.3169
Averaged Test Accurancy: 0.0000
Averaged Test AUC: 0.2801
Std Test Accurancy: 0.0000
Std Test AUC: 0.0148
--- Training 20 clients ---
> Post-training selection: choosing 10 from 20 trained clients.
>   (Using local models as metric for DivFL)
>> similarity: 100%|██████████████████████████| 400/400 [00:04<00:00, 82.15it/s]
> Aggregating models from 10 final selected clients.
> Selected client IDs for this round: [0, 3, 6, 9, 12, 13, 15, 16, 18, 19]
------------------------- time cost ------------------------- 131.2318820953369

------------- Round 1-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 1.6538
Averaged Test Accurancy: 0.3426
Averaged Test AUC: 0.8131
Std Test Accurancy: 0.0991
Std Test AUC: 0.0351
--- Training 20 clients ---
> Post-training selection: choosing 10 from 20 trained clients.
>   (Using local models as metric for DivFL)
>> similarity: 100%|██████████████████████████| 400/400 [00:04<00:00, 81.76it/s]
> Aggregating models from 10 final selected clients.
> Selected client IDs for this round: [0, 2, 3, 6, 7, 9, 13, 14, 15, 18]
------------------------- time cost ------------------------- 99.94206929206848

------------- Round 2-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 1.1165
Averaged Test Accurancy: 0.5386
Averaged Test AUC: 0.8980
Std Test Accurancy: 0.1383
Std Test AUC: 0.0351
--- Training 20 clients ---
> Post-training selection: choosing 10 from 20 trained clients.
>   (Using local models as metric for DivFL)
>> similarity: 100%|██████████████████████████| 400/400 [00:04<00:00, 85.72it/s]
> Aggregating models from 10 final selected clients.
> Selected client IDs for this round: [0, 4, 6, 7, 10, 15, 16, 17, 18, 19]
------------------------- time cost ------------------------- 102.81231331825256

------------- Round 3-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.6957
Averaged Test Accurancy: 0.6685
Averaged Test AUC: 0.9314
Std Test Accurancy: 0.1368
Std Test AUC: 0.0238
--- Training 20 clients ---
> Post-training selection: choosing 10 from 20 trained clients.
>   (Using local models as metric for DivFL)
>> similarity: 100%|██████████████████████████| 400/400 [00:04<00:00, 84.25it/s]
> Aggregating models from 10 final selected clients.
> Selected client IDs for this round: [0, 1, 2, 4, 7, 8, 9, 10, 15, 16]
------------------------- time cost ------------------------- 104.49574208259583

------------- Round 4-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.4202
Averaged Test Accurancy: 0.7975
Averaged Test AUC: 0.9361
Std Test Accurancy: 0.1085
Std Test AUC: 0.0236
--- Training 20 clients ---
> Post-training selection: choosing 10 from 20 trained clients.
>   (Using local models as metric for DivFL)
>> similarity: 100%|██████████████████████████| 400/400 [00:04<00:00, 84.28it/s]
> Aggregating models from 10 final selected clients.
> Selected client IDs for this round: [3, 6, 7, 9, 10, 12, 15, 16, 18, 19]
------------------------- time cost ------------------------- 103.41100764274597

------------- Round 5-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.2803
Averaged Test Accurancy: 0.8452
Averaged Test AUC: 0.9416
Std Test Accurancy: 0.1430
Std Test AUC: 0.0214
--- Training 20 clients ---
> Post-training selection: choosing 10 from 20 trained clients.
>   (Using local models as metric for DivFL)
>> similarity: 100%|██████████████████████████| 400/400 [00:04<00:00, 80.97it/s]
> Aggregating models from 10 final selected clients.
> Selected client IDs for this round: [2, 3, 5, 7, 8, 9, 14, 15, 16, 17]
------------------------- time cost ------------------------- 120.65044260025024

------------- Round 6-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.1254
Averaged Test Accurancy: 0.9386
Averaged Test AUC: 0.9486
Std Test Accurancy: 0.0535
Std Test AUC: 0.0159
--- Training 20 clients ---
> Post-training selection: choosing 10 from 20 trained clients.
>   (Using local models as metric for DivFL)
>> similarity: 100%|██████████████████████████| 400/400 [00:07<00:00, 52.47it/s]
> Aggregating models from 10 final selected clients.
> Selected client IDs for this round: [0, 3, 8, 9, 10, 12, 13, 15, 16, 19]
------------------------- time cost ------------------------- 155.82865691184998

------------- Round 7-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.0871
Averaged Test Accurancy: 0.9482
Averaged Test AUC: 0.9502
Std Test Accurancy: 0.0636
Std Test AUC: 0.0174
--- Training 20 clients ---
> Post-training selection: choosing 10 from 20 trained clients.
>   (Using local models as metric for DivFL)
>> similarity: 100%|██████████████████████████| 400/400 [00:07<00:00, 54.93it/s]
> Aggregating models from 10 final selected clients.
> Selected client IDs for this round: [3, 5, 6, 7, 9, 10, 12, 15, 16, 18]
------------------------- time cost ------------------------- 179.2508261203766

------------- Round 8-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.0644
Averaged Test Accurancy: 0.9599
Averaged Test AUC: 0.9514
Std Test Accurancy: 0.0454
Std Test AUC: 0.0170
--- Training 20 clients ---
> Post-training selection: choosing 10 from 20 trained clients.
>   (Using local models as metric for DivFL)
>> similarity: 100%|██████████████████████████| 400/400 [00:07<00:00, 54.43it/s]
> Aggregating models from 10 final selected clients.
> Selected client IDs for this round: [3, 5, 7, 9, 10, 11, 12, 15, 16, 18]
------------------------- time cost ------------------------- 157.4414119720459

------------- Round 9-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.0642
Averaged Test Accurancy: 0.9650
Averaged Test AUC: 0.9526
Std Test Accurancy: 0.0456
Std Test AUC: 0.0160
--- Training 20 clients ---
> Post-training selection: choosing 10 from 20 trained clients.
>   (Using local models as metric for DivFL)
>> similarity: 100%|██████████████████████████| 400/400 [00:05<00:00, 71.64it/s]
> Aggregating models from 10 final selected clients.
> Selected client IDs for this round: [4, 7, 8, 9, 11, 12, 14, 15, 16, 19]
------------------------- time cost ------------------------- 131.464022397995

------------- Round 10-------------
> Post-training selection enabled for method 'DivFL'.
> Initializing selection method 'DivFL' with the global model.
> Sending global model to 20 clients for local training.

Evaluating global model before training...
Averaged Train Loss: 0.0371
Averaged Test Accurancy: 0.9736
Averaged Test AUC: 0.9528
Std Test Accurancy: 0.0310
Std Test AUC: 0.0159
--- Training 20 clients ---
Traceback (most recent call last):
  File "C:\Program Files\Python37\lib\runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "C:\Program Files\Python37\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_latest\main.py", line 322, in <module>
    run(args, client_selection)
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_latest\main.py", line 116, in run
    server.train()
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_latest\flcore\servers\serveravg.py", line 147, in train
    local_losses, accuracy, local_metrics = self.train_clients(clients_for_training)
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_latest\flcore\servers\serverbase.py", line 446, in train_clients
    print(f"--- Training {len(clients_to_train)} clients ---")
  File "C:\Users\owner\Downloads\Benchmark_Stage_backup2\Benchmark_Stage\system_latest\flcore\clients\clientavg.py", line 56, in train
    loss.backward()
  File "C:\Users\owner\AppData\Roaming\Python\Python37\site-packages\torch\tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\owner\AppData\Roaming\Python\Python37\site-packages\torch\autograd\__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
